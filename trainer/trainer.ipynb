{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggle/working/ocr_trainer","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:24:51.633406Z","iopub.execute_input":"2024-06-15T15:24:51.633873Z","iopub.status.idle":"2024-06-15T15:24:52.768098Z","shell.execute_reply.started":"2024-06-15T15:24:51.633839Z","shell.execute_reply":"2024-06-15T15:24:52.766597Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:25:13.875459Z","iopub.execute_input":"2024-06-15T15:25:13.876173Z","iopub.status.idle":"2024-06-15T15:25:13.884417Z","shell.execute_reply.started":"2024-06-15T15:25:13.876130Z","shell.execute_reply":"2024-06-15T15:25:13.883247Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/stephen18961/ocr_trainer.git","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:25:15.495970Z","iopub.execute_input":"2024-06-15T15:25:15.496374Z","iopub.status.idle":"2024-06-15T15:25:18.823636Z","shell.execute_reply.started":"2024-06-15T15:25:15.496342Z","shell.execute_reply":"2024-06-15T15:25:18.822005Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Cloning into 'ocr_trainer'...\nremote: Enumerating objects: 73, done.\u001b[K\nremote: Counting objects: 100% (73/73), done.\u001b[K\nremote: Compressing objects: 100% (60/60), done.\u001b[K\nremote: Total 73 (delta 4), reused 73 (delta 4), pack-reused 0\u001b[K\nUnpacking objects: 100% (73/73), 13.61 MiB | 7.95 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/ocr_trainer/trainer","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:25:22.788340Z","iopub.execute_input":"2024-06-15T15:25:22.788814Z","iopub.status.idle":"2024-06-15T15:25:22.797119Z","shell.execute_reply.started":"2024-06-15T15:25:22.788775Z","shell.execute_reply":"2024-06-15T15:25:22.795911Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/working/ocr_trainer/trainer\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install natsort","metadata":{"execution":{"iopub.status.busy":"2024-06-15T15:25:24.573542Z","iopub.execute_input":"2024-06-15T15:25:24.573961Z","iopub.status.idle":"2024-06-15T15:25:39.950165Z","shell.execute_reply.started":"2024-06-15T15:25:24.573927Z","shell.execute_reply":"2024-06-15T15:25:39.948878Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: natsort in /opt/conda/lib/python3.10/site-packages (8.4.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch.backends.cudnn as cudnn\nimport yaml\nfrom train import train\nfrom utils import AttrDict\nimport pandas as pd","metadata":{"ExecuteTime":{"end_time":"2021-07-23T04:19:23.488642Z","start_time":"2021-07-23T04:19:21.854534Z"},"execution":{"iopub.status.busy":"2024-06-15T15:25:56.662774Z","iopub.execute_input":"2024-06-15T15:25:56.663197Z","iopub.status.idle":"2024-06-15T15:25:56.670110Z","shell.execute_reply.started":"2024-06-15T15:25:56.663165Z","shell.execute_reply":"2024-06-15T15:25:56.668432Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\ncudnn.deterministic = False","metadata":{"ExecuteTime":{"end_time":"2021-07-23T04:19:23.885144Z","start_time":"2021-07-23T04:19:23.880564Z"},"code_folding":[],"execution":{"iopub.status.busy":"2024-06-15T15:25:54.450889Z","iopub.execute_input":"2024-06-15T15:25:54.451814Z","iopub.status.idle":"2024-06-15T15:25:54.457148Z","shell.execute_reply.started":"2024-06-15T15:25:54.451761Z","shell.execute_reply":"2024-06-15T15:25:54.455569Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_config(file_path):\n    with open(file_path, 'r', encoding=\"utf8\") as stream:\n        opt = yaml.safe_load(stream)\n    opt = AttrDict(opt)\n    if opt.lang_char == 'None':\n        characters = ''\n        for data in opt['select_data'].split('-'):\n            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n            all_char = ''.join(df['words'])\n            characters += ''.join(set(all_char))\n        characters = sorted(set(characters))\n        opt.character= ''.join(characters)\n    else:\n        opt.character = opt.number + opt.symbol + opt.lang_char\n    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n    return opt","metadata":{"ExecuteTime":{"end_time":"2021-07-23T04:19:24.119144Z","start_time":"2021-07-23T04:19:24.112032Z"},"code_folding":[0],"execution":{"iopub.status.busy":"2024-06-15T15:25:59.168265Z","iopub.execute_input":"2024-06-15T15:25:59.168701Z","iopub.status.idle":"2024-06-15T15:25:59.180022Z","shell.execute_reply.started":"2024-06-15T15:25:59.168667Z","shell.execute_reply":"2024-06-15T15:25:59.178569Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"opt = get_config(\"config_files/en_filtered_config.yaml\")\ntrain(opt, amp=False)","metadata":{"ExecuteTime":{"end_time":"2021-07-23T04:49:07.045060Z","start_time":"2021-07-23T04:20:15.050992Z"}},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"Filtering the images containing characters which are not in opt.character\n\nFiltering the images whose label is longer than opt.batch_max_length\n\n--------------------------------------------------------------------------------\n\ndataset_root: all_data/en_sample\n\nopt.select_data: ['all_data/en_sample']\n\nopt.batch_ratio: ['1']\n\n--------------------------------------------------------------------------------\n\ndataset_root:    all_data/en_sample\t dataset: all_data/en_sample\n\nall_data/en_sample/\n\nsub-directory:\t/.\t num samples: 18\n\nnum total samples of all_data/en_sample: 18 x 1.0 (total_data_usage_ratio) = 18\n\nnum samples of all_data/en_sample per batch: 32 x 1.0 (batch_ratio) = 32\n\n--------------------------------------------------------------------------------\n\nTotal_batch_size: 32 = 32\n\n--------------------------------------------------------------------------------\n\ndataset_root:    all_data/en_sample\t dataset: /\n\nall_data/en_sample/\n\nsub-directory:\t/.\t num samples: 18\n\n--------------------------------------------------------------------------------\n\nmodel input parameters 64 600 20 1 256 256 37 34 TPS ResNet BiLSTM CTC\n\nSkip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n\nSkip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n\nModel:\n\nDataParallel(\n\n  (module): Model(\n\n    (Transformation): TPS_SpatialTransformerNetwork(\n\n      (LocalizationNetwork): LocalizationNetwork(\n\n        (conv): Sequential(\n\n          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n          (2): ReLU(inplace=True)\n\n          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n          (6): ReLU(inplace=True)\n\n          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n          (10): ReLU(inplace=True)\n\n          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n          (14): ReLU(inplace=True)\n\n          (15): AdaptiveAvgPool2d(output_size=1)\n\n        )\n\n        (localization_fc1): Sequential(\n\n          (0): Linear(in_features=512, out_features=256, bias=True)\n\n          (1): ReLU(inplace=True)\n\n        )\n\n        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n\n      )\n\n      (GridGenerator): GridGenerator()\n\n    )\n\n    (FeatureExtraction): ResNet_FeatureExtractor(\n\n      (ConvNet): ResNet(\n\n        (conv0_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n        (bn0_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (conv0_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n        (bn0_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (relu): ReLU(inplace=True)\n\n        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n        (layer1): Sequential(\n\n          (0): BasicBlock(\n\n            (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n            (downsample): Sequential(\n\n              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\n              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            )\n\n          )\n\n        )\n\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\n        (layer2): Sequential(\n\n          (0): BasicBlock(\n\n            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n            (downsample): Sequential(\n\n              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            )\n\n          )\n\n          (1): BasicBlock(\n\n            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n        )\n\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n\n        (layer3): Sequential(\n\n          (0): BasicBlock(\n\n            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n            (downsample): Sequential(\n\n              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            )\n\n          )\n\n          (1): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n          (2): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n          (3): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n          (4): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n        )\n\n        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (layer4): Sequential(\n\n          (0): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n          (1): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n          (2): BasicBlock(\n\n            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\n            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n            (relu): ReLU(inplace=True)\n\n          )\n\n        )\n\n        (conv4_1): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n\n        (bn4_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        (conv4_2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), bias=False)\n\n        (bn4_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n      )\n\n    )\n\n    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n\n    (SequenceModeling): Sequential(\n\n      (0): BidirectionalLSTM(\n\n        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n\n        (linear): Linear(in_features=512, out_features=256, bias=True)\n\n      )\n\n      (1): BidirectionalLSTM(\n\n        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n\n        (linear): Linear(in_features=512, out_features=256, bias=True)\n\n      )\n\n    )\n\n    (Prediction): Linear(in_features=256, out_features=37, bias=True)\n\n  )\n\n)\n\nModules, Parameters\n\nmodule.Transformation.LocalizationNetwork.conv.0.weight 576\n\nmodule.Transformation.LocalizationNetwork.conv.1.weight 64\n\nmodule.Transformation.LocalizationNetwork.conv.1.bias 64\n\nmodule.Transformation.LocalizationNetwork.conv.4.weight 73728\n\nmodule.Transformation.LocalizationNetwork.conv.5.weight 128\n\nmodule.Transformation.LocalizationNetwork.conv.5.bias 128\n\nmodule.Transformation.LocalizationNetwork.conv.8.weight 294912\n\nmodule.Transformation.LocalizationNetwork.conv.9.weight 256\n\nmodule.Transformation.LocalizationNetwork.conv.9.bias 256\n\nmodule.Transformation.LocalizationNetwork.conv.12.weight 1179648\n\nmodule.Transformation.LocalizationNetwork.conv.13.weight 512\n\nmodule.Transformation.LocalizationNetwork.conv.13.bias 512\n\nmodule.Transformation.LocalizationNetwork.localization_fc1.0.weight 131072\n\nmodule.Transformation.LocalizationNetwork.localization_fc1.0.bias 256\n\nmodule.Transformation.LocalizationNetwork.localization_fc2.weight 10240\n\nmodule.Transformation.LocalizationNetwork.localization_fc2.bias 40\n\nmodule.FeatureExtraction.ConvNet.conv0_1.weight 144\n\nmodule.FeatureExtraction.ConvNet.bn0_1.weight 16\n\nmodule.FeatureExtraction.ConvNet.bn0_1.bias 16\n\nmodule.FeatureExtraction.ConvNet.conv0_2.weight 4608\n\nmodule.FeatureExtraction.ConvNet.bn0_2.weight 32\n\nmodule.FeatureExtraction.ConvNet.bn0_2.bias 32\n\nmodule.FeatureExtraction.ConvNet.layer1.0.conv1.weight 18432\n\nmodule.FeatureExtraction.ConvNet.layer1.0.bn1.weight 64\n\nmodule.FeatureExtraction.ConvNet.layer1.0.bn1.bias 64\n\nmodule.FeatureExtraction.ConvNet.layer1.0.conv2.weight 36864\n\nmodule.FeatureExtraction.ConvNet.layer1.0.bn2.weight 64\n\nmodule.FeatureExtraction.ConvNet.layer1.0.bn2.bias 64\n\nmodule.FeatureExtraction.ConvNet.layer1.0.downsample.0.weight 2048\n\nmodule.FeatureExtraction.ConvNet.layer1.0.downsample.1.weight 64\n\nmodule.FeatureExtraction.ConvNet.layer1.0.downsample.1.bias 64\n\nmodule.FeatureExtraction.ConvNet.conv1.weight 36864\n\nmodule.FeatureExtraction.ConvNet.bn1.weight 64\n\nmodule.FeatureExtraction.ConvNet.bn1.bias 64\n\nmodule.FeatureExtraction.ConvNet.layer2.0.conv1.weight 73728\n\nmodule.FeatureExtraction.ConvNet.layer2.0.bn1.weight 128\n\nmodule.FeatureExtraction.ConvNet.layer2.0.bn1.bias 128\n\nmodule.FeatureExtraction.ConvNet.layer2.0.conv2.weight 147456\n\nmodule.FeatureExtraction.ConvNet.layer2.0.bn2.weight 128\n\nmodule.FeatureExtraction.ConvNet.layer2.0.bn2.bias 128\n\nmodule.FeatureExtraction.ConvNet.layer2.0.downsample.0.weight 8192\n\nmodule.FeatureExtraction.ConvNet.layer2.0.downsample.1.weight 128\n\nmodule.FeatureExtraction.ConvNet.layer2.0.downsample.1.bias 128\n\nmodule.FeatureExtraction.ConvNet.layer2.1.conv1.weight 147456\n\nmodule.FeatureExtraction.ConvNet.layer2.1.bn1.weight 128\n\nmodule.FeatureExtraction.ConvNet.layer2.1.bn1.bias 128\n\nmodule.FeatureExtraction.ConvNet.layer2.1.conv2.weight 147456\n\nmodule.FeatureExtraction.ConvNet.layer2.1.bn2.weight 128\n\nmodule.FeatureExtraction.ConvNet.layer2.1.bn2.bias 128\n\nmodule.FeatureExtraction.ConvNet.conv2.weight 147456\n\nmodule.FeatureExtraction.ConvNet.bn2.weight 128\n\nmodule.FeatureExtraction.ConvNet.bn2.bias 128\n\nmodule.FeatureExtraction.ConvNet.layer3.0.conv1.weight 294912\n\nmodule.FeatureExtraction.ConvNet.layer3.0.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.0.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.0.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.0.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.0.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.0.downsample.0.weight 32768\n\nmodule.FeatureExtraction.ConvNet.layer3.0.downsample.1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.0.downsample.1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.1.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.1.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.1.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.1.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.1.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.1.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.2.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.2.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.2.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.2.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.2.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.2.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.3.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.3.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.3.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.3.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.3.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.3.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.4.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.4.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.4.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer3.4.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer3.4.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer3.4.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.conv3.weight 589824\n\nmodule.FeatureExtraction.ConvNet.bn3.weight 256\n\nmodule.FeatureExtraction.ConvNet.bn3.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.0.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.0.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.0.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.0.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.0.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.0.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.1.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.1.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.1.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.1.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.1.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.1.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.2.conv1.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.2.bn1.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.2.bn1.bias 256\n\nmodule.FeatureExtraction.ConvNet.layer4.2.conv2.weight 589824\n\nmodule.FeatureExtraction.ConvNet.layer4.2.bn2.weight 256\n\nmodule.FeatureExtraction.ConvNet.layer4.2.bn2.bias 256\n\nmodule.FeatureExtraction.ConvNet.conv4_1.weight 262144\n\nmodule.FeatureExtraction.ConvNet.bn4_1.weight 256\n\nmodule.FeatureExtraction.ConvNet.bn4_1.bias 256\n\nmodule.FeatureExtraction.ConvNet.conv4_2.weight 262144\n\nmodule.FeatureExtraction.ConvNet.bn4_2.weight 256\n\nmodule.FeatureExtraction.ConvNet.bn4_2.bias 256\n\nmodule.SequenceModeling.0.rnn.weight_ih_l0 262144\n\nmodule.SequenceModeling.0.rnn.weight_hh_l0 262144\n\nmodule.SequenceModeling.0.rnn.bias_ih_l0 1024\n\nmodule.SequenceModeling.0.rnn.bias_hh_l0 1024\n\nmodule.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n\nmodule.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n\nmodule.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n\nmodule.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n\nmodule.SequenceModeling.0.linear.weight 131072\n\nmodule.SequenceModeling.0.linear.bias 256\n\nmodule.SequenceModeling.1.rnn.weight_ih_l0 262144\n\nmodule.SequenceModeling.1.rnn.weight_hh_l0 262144\n\nmodule.SequenceModeling.1.rnn.bias_ih_l0 1024\n\nmodule.SequenceModeling.1.rnn.bias_hh_l0 1024\n\nmodule.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n\nmodule.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n\nmodule.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n\nmodule.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n\nmodule.SequenceModeling.1.linear.weight 131072\n\nmodule.SequenceModeling.1.linear.bias 256\n\nmodule.Prediction.weight 9472\n\nmodule.Prediction.bias 37\n\nTotal Trainable Params: 15142141\n\nTrainable params num :  15142141\n\nOptimizer:\n\nAdadelta (\n\nParameter Group 0\n\n    differentiable: False\n\n    eps: 1e-08\n\n    foreach: None\n\n    lr: 1.0\n\n    maximize: False\n\n    rho: 0.95\n\n    weight_decay: 0\n\n)\n\n------------ Options -------------\n\nnumber: 0123456789\n\nsymbol: \n\nlang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n\nexperiment_name: en_filtered\n\ntrain_data: all_data/en_sample\n\nvalid_data: all_data/en_sample\n\nmanualSeed: 1111\n\nworkers: 6\n\nbatch_size: 32\n\nnum_iter: 300000\n\nvalInterval: 20000\n\nsaved_model: \n\nFT: False\n\noptim: False\n\nlr: 1.0\n\nbeta1: 0.9\n\nrho: 0.95\n\neps: 1e-08\n\ngrad_clip: 5\n\nselect_data: ['all_data/en_sample']\n\nbatch_ratio: ['1']\n\ntotal_data_usage_ratio: 1.0\n\nbatch_max_length: 34\n\nimgH: 64\n\nimgW: 600\n\nrgb: False\n\ncontrast_adjust: 0.0\n\nsensitive: True\n\nPAD: True\n\ndata_filtering_off: False\n\nTransformation: TPS\n\nFeatureExtraction: ResNet\n\nSequenceModeling: BiLSTM\n\nPrediction: CTC\n\nnum_fiducial: 20\n\ninput_channel: 1\n\noutput_channel: 256\n\nhidden_size: 256\n\ndecode: greedy\n\nnew_prediction: False\n\nfreeze_FeatureFxtraction: False\n\nfreeze_SequenceModeling: False\n\ncharacter: 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\n\nnum_class: 37\n\n---------------------------------------\n\n\n"},{"name":"stderr","output_type":"stream","text":"c:\\python\\Lib\\site-packages\\torch\\nn\\functional.py:4343: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n\n  warnings.warn(\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)","File \u001b[1;32mc:\\Projects\\ANPR\\datasets\\ocr\\train_ocr\\trainer\\dataset.py:115\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     image, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_loader_iter)\n\u001b[0;32m    116\u001b[0m     balanced_batch_images\u001b[38;5;241m.\u001b[39mappend(image)\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1319\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_workers()\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \n\u001b[0;32m   1323\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n","\u001b[1;31mStopIteration\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m opt \u001b[38;5;241m=\u001b[39m get_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_files/en_filtered_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Projects\\ANPR\\datasets\\ocr\\train_ocr\\trainer\\train.py:203\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt, show_number, amp)\u001b[0m\n\u001b[0;32m    201\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     image_tensors, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     image \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    205\u001b[0m     text, length \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mencode(labels, batch_max_length\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mbatch_max_length)\n","File \u001b[1;32mc:\\Projects\\ANPR\\datasets\\ocr\\train_ocr\\trainer\\dataset.py:120\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter_list[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader_list[i])\n\u001b[1;32m--> 120\u001b[0m     image, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter_list[i])\n\u001b[0;32m    121\u001b[0m     balanced_batch_images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m    122\u001b[0m     balanced_batch_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[1;32mc:\\python\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n","File \u001b[1;32mc:\\python\\Lib\\threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}